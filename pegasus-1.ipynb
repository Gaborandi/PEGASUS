{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\user\\anaconda3\\lib\\site-packages (1.9.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\user\\anaconda3\\lib\\site-packages (0.10.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\user\\anaconda3\\lib\\site-packages (0.9.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from torch) (3.7.4.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from torchvision) (1.19.5)\n",
      "Requirement already satisfied: pillow>=5.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torchvision) (8.3.2)\n"
     ]
    }
   ],
   "source": [
    "#install dependencies (Pytorch)\n",
    "\n",
    "!pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\user\\anaconda3\\lib\\site-packages (4.11.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.0.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (0.0.18)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (0.0.46)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from transformers) (4.8.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (4.42.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (5.3.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (2021.8.28)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from transformers) (20.1)\n",
      "Requirement already satisfied: ruamel.yaml==0.17.16 in c:\\users\\user\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.0.17->transformers) (0.17.16)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from huggingface-hub>=0.0.17->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: click in c:\\users\\user\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: six in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\user\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (0.14.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from requests->transformers) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from requests->transformers) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\appdata\\roaming\\python\\python37\\site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.1.2; platform_python_implementation == \"CPython\" and python_version < \"3.10\" in c:\\users\\user\\anaconda3\\lib\\site-packages (from ruamel.yaml==0.17.16->huggingface-hub>=0.0.17->transformers) (0.2.6)\n"
     ]
    }
   ],
   "source": [
    "#install huggingface transformers\n",
    "\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import and load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dependencies from transfoermers \n",
    "#if you can't load (pegasustokenizer), use this command on your CMD \"pip install sentencepiece\",then restart kernel\n",
    "#then load the next code again\n",
    "\n",
    "from transformers import PegasusForConditionalGeneration , PegasusTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f13bd31f1454bf2903f3b21b51f421d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1912529.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44af110f9f7b4755b61c37802d820765",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=65.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d45e47b60f7a464fa75a0a6ac2a442d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=87.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76860be01bcf49569da6653010544dcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=3520083.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#load tokenizer \n",
    "# we can change the model from this website (\"https://huggingface.co/models?sort=downloads\")\n",
    "\n",
    "token = PegasusTokenizer.from_pretrained(\"google/pegasus-xsum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dc69ded520f47df882b62ad45b2f4e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=2275329241.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "\n",
    "model = PegasusForConditionalGeneration.from_pretrained(\"google/pegasus-xsum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "perform Abdstractive summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "lbert Einstein was born at Ulm, in Württemberg, Germany, on March 14, 1879. Six weeks later the family moved \n",
    "to Munich, where he later on began his schooling at the Luitpold Gymnasium. Later, they moved to Italy and Albert \n",
    "continued his education at Aarau, Switzerland and in 1896 he entered the Swiss Federal Polytechnic School in Zurich\n",
    "to be trained as a teacher in physics and mathematics. In 1901, the year he gained his diploma, he acquired Swiss \n",
    "citizenship and, as he was unable to find a teaching post, he accepted a position as technical assistant in the\n",
    "Swiss Patent Office. In 1905 he obtained his doctor’s degree. During his stay at the Patent Office, and in his spare \n",
    "time, he produced much of his remarkable work and in 1908 he was appointed Privatdozent in Berne. In 1909 he became \n",
    "Professor Extraordinary at Zurich, in 1911 Professor of Theoretical Physics at Prague, returning to Zurich in the \n",
    "following year to fill a similar post. In 1914 he was appointed Director of the Kaiser Wilhelm Physical Institute \n",
    "and Professor in the University of Berlin. He became a German citizen in 1914 and remained in Berlin until 1933 \n",
    "when he renounced his citizenship for political reasons and emigrated to America to take the position of Professor \n",
    "of Theoretical Physics at Princeton*. He became a United States citizen in 1940 and retired from his post in 1945.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  110, 55423, 22726,   140,  1723,   134, 20550,   208,   108,   115,\n",
       "          1354,   105, 86418,   108,  2579,   108,   124,  1051,  7914, 47147,\n",
       "           107,  7651,   899,   678,   109,   328,  1652,   112, 14120,   108,\n",
       "           241,   178,   678,   124,  1219,   169, 17176,   134,   109,  8732,\n",
       "          1418,  1379,  1623, 76230,   107,  8280,   108,   157,  1652,   112,\n",
       "          3397,   111,  8639,  2059,   169,   798,   134,   202,  2915,  4380,\n",
       "           108,  7317,   111,   115, 35511,   178,  3295,   109,  7041,  3535,\n",
       "         28589,   760,   115, 21813,   112,   129,  2492,   130,   114,  2118,\n",
       "           115,  8343,   111, 10045,   107,   222, 28559,   108,   109,   232,\n",
       "           178,  4119,   169, 13789,   108,   178,  4540,  7041, 12485,   111,\n",
       "           108,   130,   178,   140,  3231,   112,   258,   114,  1703,   450,\n",
       "           108,   178,  2842,   114,   975,   130,  1611,  4627,   115,   109,\n",
       "          7041, 16255,  1584,   107,   222, 28613,   178,  3686,   169,  2214,\n",
       "           123,   116,  1393,   107,  2348,   169,   753,   134,   109, 16255,\n",
       "          1584,   108,   111,   115,   169,  5170,   166,   108,   178,  1788,\n",
       "           249,   113,   169,  5157,   201,   111,   115, 27764,   178,   140,\n",
       "          4486, 84694, 48915,   144,   115, 63480,   107,   222, 33379,   178,\n",
       "          1257,  3973, 33891,   134, 21813,   108,   115, 22399,  3973,   113,\n",
       "         54010, 12381,   134, 14098,   108,  4319,   112, 21813,   115,   109,\n",
       "           645,   232,   112,  1738,   114,   984,   450,   107,   222, 22157,\n",
       "           178,   140,  4486,  1970,   113,   109, 25533, 42022,  9135,  1821,\n",
       "           111,  3973,   115,   109,   502,   113,  5991,   107,   285,  1257,\n",
       "           114,  2546,  7776,   115, 22157,   111,  4615,   115,  5991,   430,\n",
       "         22106,   173,   178, 58413,   252,   169, 12485,   118,  1488,  1523,\n",
       "           111, 52975,   112,  1086,   112,   248,   109,   975,   113,  3973,\n",
       "           113, 54010, 12381,   134, 16267,  1109,   107,   285,  1257,   114,\n",
       "           706,  1013,  7776,   115, 11324,   111,  5774,   135,   169,   450,\n",
       "           115, 41699,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create tokens (number representation of words)\n",
    "\n",
    "tokens = token(text, truncation = True , padding = \"longest\", return_tensors = \"pt\")\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary\n",
    "summary = model.generate(**tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  110, 55423, 22726,   140,  1723,   134, 20550,   208,   108,   115,\n",
       "           1354,   105, 86418,   108,  2579,   108,   124,  1051,  7914, 47147,\n",
       "            107,  7651,   899,   678,   109,   328,  1652,   112, 14120,   108,\n",
       "            241,   178,   678,   124,  1219,   169, 17176,   134,   109,  8732,\n",
       "           1418,  1379,  1623, 76230,   107,  8280,   108,   157,  1652,   112,\n",
       "           3397,   111,  8639,  2059,   169,   798,   134,   202,  2915,  4380,\n",
       "            108,  7317,   111,   115, 35511,   178,  3295,   109,  7041,  3535,\n",
       "          28589,   760,   115, 21813,   112,   129,  2492,   130,   114,  2118,\n",
       "            115,  8343,   111, 10045,   107,   222, 28559,   108,   109,   232,\n",
       "            178,  4119,   169, 13789,   108,   178,  4540,  7041, 12485,   111,\n",
       "            108,   130,   178,   140,  3231,   112,   258,   114,  1703,   450,\n",
       "            108,   178,  2842,   114,   975,   130,  1611,  4627,   115,   109,\n",
       "           7041, 16255,  1584,   107,   222, 28613,   178,  3686,   169,  2214,\n",
       "            123,   116,  1393,   107,  2348,   169,   753,   134,   109, 16255,\n",
       "           1584,   108,   111,   115,   169,  5170,   166,   108,   178,  1788,\n",
       "            249,   113,   169,  5157,   201,   111,   115, 27764,   178,   140,\n",
       "           4486, 84694, 48915,   144,   115, 63480,   107,   222, 33379,   178,\n",
       "           1257,  3973, 33891,   134, 21813,   108,   115, 22399,  3973,   113,\n",
       "          54010, 12381,   134, 14098,   108,  4319,   112, 21813,   115,   109,\n",
       "            645,   232,   112,  1738,   114,   984,   450,   107,   222, 22157,\n",
       "            178,   140,  4486,  1970,   113,   109, 25533, 42022,  9135,  1821,\n",
       "            111,  3973,   115,   109,   502,   113,  5991,   107,   285,  1257,\n",
       "            114,  2546,  7776,   115, 22157,   111,  4615,   115,  5991,   430,\n",
       "          22106,   173,   178, 58413,   252,   169, 12485,   118,  1488,  1523,\n",
       "            111, 52975,   112,  1086,   112,   248,   109,   975,   113,  3973,\n",
       "            113, 54010, 12381,   134, 16267,  1109,   107,   285,  1257,   114,\n",
       "            706,  1013,  7776,   115, 11324,   111,  5774,   135,   169,   450,\n",
       "            115, 41699,     1]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{**tokens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0,  8639, 22726,   140,   156,   113,   109,  2502,  4182,   113,\n",
       "          109,   599,   307,  7580,   107,     1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#summary in tokens\n",
    "\n",
    "summary[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Albert Einstein was one of the greatest scientists of the 20th Century.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#decoding the tokens into words \n",
    "\n",
    "token.decode(summary[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
